{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Project_1  V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcMDMQ7d2SpjJSLovPsOz+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-Dirir/COSC606_Project1_Ahmed_Dirir/blob/master/Machine_Learning_Project_1_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQIwbD35Eed",
        "colab_type": "code",
        "outputId": "9806fbb1-749e-4fad-b982-37b9d9de2348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7POxBlR9MJIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global Setup\n",
        "np.random.seed(30)\n",
        "learning_rate = 0.1\n",
        "num_epochs = 2000\n",
        "cost_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewOhDMN79olV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReLULayer:\n",
        "  def __init__(self, shape):\n",
        "    self.A = np.zeros((shape))\n",
        "\n",
        "  def forward(self, Z):\n",
        "    self.A =  Z * (Z > 0)\n",
        "\n",
        "  def backward(self, upstream_grad):\n",
        "    self.dz = upstream_grad * (1. * (self.A > 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp_jzEAc5sRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearLayer:\n",
        "  def __init__(self, input_shape, n_out, init_type='plain'):\n",
        "    self.m = input_shape[1]\n",
        "    self.initialize_parameters(input_shape[0], n_out, init_type)\n",
        "    self.Z = np.zeros((self.params['W'].shape[0], input_shape[1]))\n",
        "\n",
        "  def forward(self, A_prev):\n",
        "    self.A_prev = A_prev\n",
        "    self.Z = np.dot(self.params['W'], self.A_prev) + self.params['b']\n",
        "\n",
        "  def backward(self, upstream_grad):\n",
        "    self.dW = np.dot(upstream_grad, self.A_prev.T)\n",
        "    self.db = np.sum(upstream_grad, axis=1, keepdims=True)\n",
        "    self.dA_prev = np.dot(self.params['W'].T, upstream_grad)\n",
        "\n",
        "  def update_params(self, learning_rate=0.1):\n",
        "    self.params['W'] = self.params['W'] - learning_rate * self.dW\n",
        "    self.params['b'] = self.params['b'] - learning_rate * self.db\n",
        "\n",
        "  def initialize_parameters(self,n_in, n_out, init_type='plain'):\n",
        "    self.params = dict()\n",
        "    if init_type == 'plain':\n",
        "      self.params['W'] = np.random.randn(n_out, n_in) * 0.1\n",
        "    elif init_type == 'xavier':\n",
        "      self.params['W'] = np.random.randn(n_out, n_in) / (np.sqrt(n_in))\n",
        "    elif init_type == 'he':\n",
        "      self.params['W'] = np.random.randn(n_out, n_in) * np.sqrt(2/n_in)\n",
        "\n",
        "    self.params['b'] = np.zeros((n_out, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHodY7jJZMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Helper_functions:\n",
        "  def compute_cost(self, Y, Y_hat):\n",
        "    m = Y.shape[1]\n",
        "    cost = ((1 / (2 * m)) * np.sum(np.square(Y - Y_hat)))\n",
        "    cost = np.squeeze(cost)\n",
        "    dY_hat = -1 / m * (Y - Y_hat)\n",
        "\n",
        "    return cost, dY_hat\n",
        "\n",
        "  def plot_learning_curve(self,costs, learning_rate, total_epochs, save=False):\n",
        "    plt.figure()\n",
        "\n",
        "    steps = int(total_epochs / len(costs))  # the steps at with costs were recorded\n",
        "    plt.ylabel('Cost')\n",
        "    plt.xlabel('Iterations ')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.xticks(locs[1:-1], tuple(np.array(locs[1:-1], dtype='int')*steps))  # change x labels of the plot\n",
        "    plt.xticks()\n",
        "    if save:\n",
        "        plt.savefig('Cost_Curve_ReLU.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "  def datasets_processing(self):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    training_examples = tf.keras.utils.normalize(x_train)\n",
        "    training_examples = training_examples.reshape((training_examples.shape[0], 784))\n",
        "    testing_examples = tf.keras.utils.normalize(x_test)\n",
        "    testing_examples = x_test.reshape((testing_examples.shape[0], 784))\n",
        "\n",
        "    count = np.zeros((10))\n",
        "    threshold = 5000\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "\n",
        "    for i in range(training_examples.shape[0]):\n",
        "      if count[y_train[i]] < threshold:\n",
        "        X_train += [training_examples[i]]\n",
        "        y_tmp = np.zeros((10))\n",
        "        y_tmp[y_train[i]] = 1\n",
        "        Y_train += [y_tmp]\n",
        "        count[y_train[i]] += 1\n",
        "\n",
        "    training_examples = np.array(X_train).T\n",
        "    training_examples_output = np.array(Y_train).T\n",
        "    testing_examples = np.array(testing_examples).T\n",
        "    testing_examples_output = np.array(y_test).T\n",
        "\n",
        "    return (training_examples, training_examples_output), (testing_examples, testing_examples_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tHNoJolBt5K",
        "colab_type": "code",
        "outputId": "4cd22000-8808-4738-ae10-57d7a0b15905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Data PreProcessing and Build the neural network model\n",
        "helper_functions = Helper_functions()\n",
        "\n",
        "(training_examples, training_examples_output), (testing_examples, testing_examples_output) = helper_functions.datasets_processing()\n",
        "\n",
        "print('Training set is: ' + str(training_examples.shape))\n",
        "print('Training set output is: ' + str(training_examples_output.shape))\n",
        "print('Testing set is: ' + str(testing_examples.shape))\n",
        "print('Testing set output is: ' + str(testing_examples_output.shape))\n",
        "\n",
        "Z1 = LinearLayer(input_shape=training_examples.shape, n_out=128, init_type='plain')\n",
        "A1 = ReLULayer(Z1.Z.shape)\n",
        "\n",
        "Z3 = LinearLayer(input_shape=A1.A.shape, n_out=10, init_type='plain')\n",
        "A3 = ReLULayer(Z3.Z.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set is: (784, 50000)\n",
            "Training set output is: (10, 50000)\n",
            "Testing set is: (784, 10000)\n",
            "Testing set output is: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU8QsXiqEGnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trainging the neural network\n",
        "for epoch in range(num_epochs):\n",
        "  start = time.time()\n",
        "  # ------------------------- forward-prop -------------------------\n",
        "  Z1.forward(training_examples)\n",
        "  A1.forward(Z1.Z)\n",
        "\n",
        "  Z3.forward(A1.A)\n",
        "  A3.forward(Z3.Z)\n",
        "\n",
        "  # ---------------------- Compute Cost ----------------------------\n",
        "  cost , dA3 = helper_functions.compute_cost(Y=training_examples_output, Y_hat=A3.A)\n",
        "  print(\"Cost at epoch#{}: {}\".format(epoch, cost))\n",
        "\n",
        "  cost_list += [cost]\n",
        "\n",
        "  # ------------------------- back-prop ---------------------------\n",
        "  \n",
        "  A3.backward(dA3)\n",
        "  Z3.backward(A3.dz)\n",
        "\n",
        "  A1.backward(Z3.dA_prev)\n",
        "  Z1.backward(A1.dz)\n",
        "\n",
        "  # ----------------------- Update weights and bias ----------------\n",
        "  Z3.update_params(learning_rate=learning_rate)\n",
        "  Z1.update_params(learning_rate=learning_rate)\n",
        "\n",
        "  end = time.time()\n",
        "  print('Execution time in seconds per epoch is ' + str(end - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd3HIXLkjA_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing the neural network\n",
        "Z1.forward(testing_examples)\n",
        "A1.forward(Z1.Z)\n",
        "\n",
        "Z3.forward(A1.A)\n",
        "A3.forward(Z3.Z)\n",
        "\n",
        "accuracy = 100 * np.sum((np.argmax(A3.A.T, axis=1) == testing_examples_output) / testing_examples_output.shape[0])\n",
        "print('Accuracy is: ' + str(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_dRmmH6LAlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cost function vs number of epochs graph\n",
        "helper_functions.plot_learning_curve(cost_list, learning_rate, len(cost_list), save=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-P159d6sRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('Cost_Curve_ReLU.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}